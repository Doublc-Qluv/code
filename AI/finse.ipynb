{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-8acc1953cd2c>:51: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# 构建和训练模型\\ndef train_and_test(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):\\n    pass\\n\\n# 划分数据集并调用train_and_test测试和验证\\ndef hold_out(images, labels, train_percentage):\\n    pass\\n\\n\\ndef cross_validation(images, labels, k):\\n    pass\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# 将 numpy 数组中的图片和标签顺序打乱\n",
    "def shuffer_images_and_labels(images, labels):\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(images)))\n",
    "    shuffled_images = images[shuffle_indices]\n",
    "    shuffled_labels = labels[shuffle_indices]\n",
    "    return shuffled_images, shuffled_labels\n",
    "\n",
    "# 将label从长度10的one hot向量转换为0~9的数字\n",
    "# 例：get_label(total_labels[0]) 获取到total_labels中第一个标签对应的数字\n",
    "def get_label(label):\n",
    "    return np.argmax(label)\n",
    "\n",
    "# images：训练集的feature部分\n",
    "# labels：训练集的label部分\n",
    "# batch_size： 每次训练的batch大小\n",
    "# epoch_num： 训练的epochs数\n",
    "# shuffle： 是否打乱数据\n",
    "# 使用示例：\n",
    "#   for (batchImages, batchLabels) in batch_iter(images_train, labels_train, batch_size, epoch_num, shuffle=True):\n",
    "#       sess.run(feed_dict={inputLayer: batchImages, outputLabel: batchLabels})\n",
    "def batch_iter(images,labels, batch_size, epoch_num, shuffle=True):\n",
    "    \n",
    "    data_size = len(images)\n",
    "    \n",
    "    num_batches_per_epoch = int(data_size / batch_size)  # 样本数/batch块大小,多出来的“尾数”，不要了\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            \n",
    "            shuffled_data_feature = images[shuffle_indices]\n",
    "            shuffled_data_label   = labels[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data_feature = images\n",
    "            shuffled_data_label = labels\n",
    "\n",
    "        for batch_num in range(num_batches_per_epoch):   # batch_num取值0到num_batches_per_epoch-1\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "\n",
    "            yield (shuffled_data_feature[start_index:end_index] , shuffled_data_label[start_index:end_index])\n",
    "\n",
    "\n",
    "# 读取数据集\n",
    "mnist = input_data.read_data_sets('./MNIST_data/', one_hot=True)\n",
    "\n",
    "total_images = mnist.train.images\n",
    "total_labels = mnist.train.labels\n",
    "total_images, total_labels = shuffer_images_and_labels(total_images, total_labels)\n",
    "\n",
    "# 简单划分前50000个为训练集，后5000个为测试集\n",
    "origin_images_train = total_images[:50000]\n",
    "origin_labels_train = total_labels[:50000]\n",
    "origin_images_test = total_images[50000:]\n",
    "origin_labels_test = total_labels[50000:]\n",
    "\n",
    "'''# 构建和训练模型\n",
    "def train_and_test(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):\n",
    "    pass\n",
    "\n",
    "# 划分数据集并调用train_and_test测试和验证\n",
    "def hold_out(images, labels, train_percentage):\n",
    "    pass\n",
    "\n",
    "\n",
    "def cross_validation(images, labels, k):\n",
    "    pass\n",
    "'''\n",
    "\n",
    "# 使用简单划分的训练集和测试集训练，并使用测试集评估模型\n",
    "# train_and_test(origin_images_train, origin_labels_train, origin_images_test, origin_labels_test, origin_images_test, origin_labels_test)\n",
    "\n",
    "# 调用函数用留出法和k折交叉验证法评估模型\n",
    "# hold_out(total_images, total_labels, 0.8)\n",
    "# cross_validation(total_images, total_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4ee8e56df436>:29: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputLayer = tf.placeholder(tf.float32,[None,784],name=\"X\")\n",
    "outputLabel = tf.placeholder(tf.float32,[None,10],name=\"Y\")\n",
    "\n",
    "H1_NN = 256\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,H1_NN]))\n",
    "b1 = tf.Variable(tf.zeros([H1_NN]))\n",
    "\n",
    "Y1 = tf.nn.relu(tf.matmul(inputLayer,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([H1_NN,10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "forward = tf.matmul(Y1,W2) + b2\n",
    "pred = tf.nn.softmax(forward)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 构建和训练模型\n",
    "\n",
    "train_loop = 50\n",
    "batch_size = 100\n",
    "#total_batch = int(mnist.train.num_examples / batch_size)\n",
    "display_step = 5\n",
    "learning_rate = 0.05\n",
    "\n",
    "#loss_function = tf.reduce_mean(-tf.reduce_sum(outputLabel*tf.log(pred),reduction_indices=1))\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward,labels=outputLabel))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "\n",
    "# 检查预测类别与实际类别的匹配情况 ， 参数1为第1维（按列），0则为按行，-1则为最后一维\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(outputLabel,1))\n",
    "\n",
    "#准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "def train_and_test(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):\n",
    "    \n",
    "    total_batch = int(images_train.shape[0] / batch_size)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(train_loop):\n",
    "        for (batchImages, batchLabels) in batch_iter(images_train, labels_train, batch_size, train_loop, shuffle=True):\n",
    "            batchImages, batchLabels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer,feed_dict={inputLayer: batchImages, outputLabel: batchLabels})\n",
    "\n",
    "        # validate\n",
    "        loss, acc = sess.run([loss_function,accuracy],\n",
    "                            feed_dict={inputLayer: images_validation, outputLabel: labels_validation})\n",
    "        \n",
    "        # output\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print(\"train epoch:%02d\" % (epoch + 1), \"Loss={:.9f}\".format(loss),\\\n",
    "                 \"accuracy: {:.4f}\".format(acc))\n",
    "\n",
    "    print(\"Train finished!\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    accu_test = sess.run(accuracy, feed_dict={inputLayer:images_test, outputLabel: labels_test})\n",
    "    print(\"Test accuracy;\",accu_test)\n",
    "    return accu_test\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分层采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_images = {}\n",
    "samp_labels = {}\n",
    "for i in range(10):\n",
    "    samp_images[i] = []\n",
    "    samp_labels[i] = []\n",
    "for i in range(total_images.shape[0]):\n",
    "    num = get_label(total_labels[i])\n",
    "    samp_images[num].append(total_images[i])\n",
    "    samp_labels[num].append(total_labels[i])\n",
    "\n",
    "# for i in range(10):\n",
    "#     samp_images[i] = np.array(samp_images[i])\n",
    "#     samp_labels[i] = np.array(samp_labels[i])\n",
    "    \n",
    "# samp_images: {  0:[[],[],[],...] , 1:[[],[],[]...] ....9:[[],[],[]...] }\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_samp(samp):\n",
    "    #print(samp.shape)\n",
    "    shuffle_indices = np.random.permutation(np.arange(samp.shape[0]))\n",
    "    samp = samp[shuffle_indices]\n",
    "\n",
    "# print(samp[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 留出法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集并调用train_and_test测试和验证\n",
    "def hold_out(train_percentage):\n",
    "    \n",
    "    n = 1\n",
    "    accu = 0.0\n",
    "    for i in range(n):\n",
    "        print(\"loop %d\" % i)\n",
    "        \n",
    "#         holdout_images_train = samp_images[0][0:2]\n",
    "#         holdout_labels_train = samp_labels[0][0:2]\n",
    "#         holdout_images_test = samp_images[0][-2:-1]\n",
    "#         holdout_labels_test = samp_labels[0][-2:-1]\n",
    "        holdout_images_train = []\n",
    "        holdout_labels_train = []\n",
    "        holdout_images_test = []\n",
    "        holdout_labels_test = []\n",
    "        \n",
    "        \n",
    "        print(\"beging generating the training and test set\")\n",
    "        # train set\n",
    "        for num in range(10):\n",
    "            num_of_batch = int(len(samp_images[num]) * train_percentage)\n",
    "            \n",
    "            holdout_images_train.extend(samp_images[num][:num_of_batch])\n",
    "            holdout_labels_train.extend(samp_labels[num][:num_of_batch])\n",
    "            holdout_images_test.extend(samp_images[num][num_of_batch:])\n",
    "            holdout_labels_test.extend(samp_labels[num][num_of_batch:])\n",
    "\n",
    "        holdout_images_train = np.array(holdout_images_train)\n",
    "        holdout_labels_train = np.array(holdout_labels_train)\n",
    "        holdout_images_test = np.array(holdout_images_test)\n",
    "        holdout_labels_test = np.array(holdout_labels_test)\n",
    "        \n",
    "        shuffle_samp(holdout_images_train)\n",
    "        shuffle_samp(holdout_labels_train)\n",
    "        shuffle_samp(holdout_images_test)\n",
    "        shuffle_samp(holdout_labels_test)\n",
    "            \n",
    "              \n",
    "        accu += train_and_test(holdout_images_train, holdout_labels_train, holdout_images_test, holdout_labels_test, holdout_images_test, holdout_labels_test)\n",
    "\n",
    "\n",
    "    print(\"after %d trainings,accuracy=\" % n, accu / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k=10):\n",
    "    \n",
    "    accu = 0.0\n",
    "    \n",
    "    image_groups = []\n",
    "    label_groups = []\n",
    "    \n",
    "    \n",
    "    for i in range(k):\n",
    "        image_groups.append([])\n",
    "        label_groups.append([])\n",
    "        \n",
    "    for i in range(10):\n",
    "        \n",
    "        group_len_of_this_num = len(samp_images[i]) // k\n",
    "        \n",
    "        ind= 0\n",
    "        for j in range(k-1):\n",
    "            image_groups[j].extend(samp_images[i][ind : ind + group_len_of_this_num])\n",
    "            label_groups[j].extend(samp_labels[i][ind : ind + group_len_of_this_num])\n",
    "            ind += group_len_of_this_num\n",
    "        image_groups[k-1].extend(samp_images[i][ind:])\n",
    "        label_groups[k-1].extend(samp_labels[i][ind:])\n",
    "        \n",
    "    \n",
    "    for i in range(k):\n",
    "        \n",
    "        print(\"loop %d begins\" % (i+1))\n",
    "        \n",
    "        cross_images_train = []\n",
    "        cross_labels_train = []\n",
    "        cross_images_test = []\n",
    "        cross_labels_test = []\n",
    "        \n",
    "        cross_images_test.extend(image_groups[i])\n",
    "        cross_labels_test.extend(label_groups[i])\n",
    "        for j in range(k):\n",
    "            if j != k:\n",
    "                cross_images_train.extend(image_groups[j])\n",
    "                cross_labels_train.extend(label_groups[j])\n",
    "            \n",
    "        cross_images_train = np.array(cross_images_train)\n",
    "        cross_labels_train = np.array( cross_labels_train)\n",
    "        cross_images_test = np.array(cross_images_test)\n",
    "        cross_labels_test = np.array(cross_labels_test)\n",
    "        \n",
    "        shuffle_samp(cross_images_train)\n",
    "        shuffle_samp(cross_labels_train)\n",
    "        shuffle_samp(cross_images_test)\n",
    "        shuffle_samp(cross_labels_test)\n",
    "        \n",
    "        \n",
    "        accu += train_and_test(cross_images_train, cross_labels_train, cross_images_test, cross_labels_test, cross_images_test, cross_labels_test)\n",
    "\n",
    "    \n",
    "    print(\"after %d trainings,accuracy=\" % k, accu / k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "### normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch:05 Loss=0.000916207 accuracy: 1.0000\n",
      "train epoch:10 Loss=0.000388387 accuracy: 1.0000\n",
      "train epoch:15 Loss=0.000246479 accuracy: 1.0000\n",
      "train epoch:20 Loss=0.000183177 accuracy: 1.0000\n",
      "train epoch:25 Loss=0.000141516 accuracy: 1.0000\n",
      "train epoch:30 Loss=0.000116244 accuracy: 1.0000\n",
      "train epoch:35 Loss=0.000098589 accuracy: 1.0000\n",
      "train epoch:40 Loss=0.000085399 accuracy: 1.0000\n",
      "train epoch:45 Loss=0.000075346 accuracy: 1.0000\n",
      "train epoch:50 Loss=0.000067325 accuracy: 1.0000\n",
      "Train finished!\n",
      "Test accuracy; 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用简单划分的训练集和测试集训练，并使用测试集评估模型\n",
    "train_and_test(origin_images_train, origin_labels_train, origin_images_test, origin_labels_test, \\\n",
    "               origin_images_test, origin_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hold out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 1 begins\n",
      "train epoch:05 Loss=0.000677065 accuracy: 1.0000\n",
      "train epoch:10 Loss=0.000294698 accuracy: 1.0000\n",
      "train epoch:15 Loss=0.000187700 accuracy: 1.0000\n",
      "train epoch:20 Loss=0.000138071 accuracy: 1.0000\n",
      "train epoch:25 Loss=0.000108107 accuracy: 1.0000\n",
      "train epoch:30 Loss=0.000088957 accuracy: 1.0000\n",
      "train epoch:35 Loss=0.000075180 accuracy: 1.0000\n",
      "train epoch:40 Loss=0.000065259 accuracy: 1.0000\n",
      "train epoch:45 Loss=0.000057531 accuracy: 1.0000\n",
      "train epoch:50 Loss=0.000051412 accuracy: 1.0000\n",
      "Train finished!\n",
      "Test accuracy; 1.0\n",
      "loop 2 begins\n",
      "train epoch:05 Loss=0.000759807 accuracy: 1.0000\n",
      "train epoch:10 Loss=0.000332537 accuracy: 1.0000\n",
      "train epoch:15 Loss=0.000208788 accuracy: 1.0000\n",
      "train epoch:20 Loss=0.000152840 accuracy: 1.0000\n",
      "train epoch:25 Loss=0.000119544 accuracy: 1.0000\n",
      "train epoch:30 Loss=0.000098162 accuracy: 1.0000\n",
      "train epoch:35 Loss=0.000083312 accuracy: 1.0000\n",
      "train epoch:40 Loss=0.000071927 accuracy: 1.0000\n",
      "train epoch:45 Loss=0.000063675 accuracy: 1.0000\n",
      "train epoch:50 Loss=0.000056763 accuracy: 1.0000\n",
      "Train finished!\n",
      "Test accuracy; 1.0\n",
      "loop 3 begins\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-92eca7edcf5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 调用k折交叉验证法评估模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-aaf5ef9c4a32>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0maccu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_images_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_images_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_labels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_images_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_labels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ee8e56df436>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(images_train, labels_train, images_test, labels_test, images_validation, labels_validation)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatchImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchLabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbatchImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputLayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputLabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 调用k折交叉验证法评估模型\n",
    "cross_validation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
