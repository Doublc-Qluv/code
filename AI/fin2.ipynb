{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-587a66dac93a>:48: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 将 numpy 数组中的图片和标签顺序打乱\n",
    "def shuffer_images_and_labels(images, labels):\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(images)))\n",
    "    shuffled_images = images[shuffle_indices]\n",
    "    shuffled_labels = labels[shuffle_indices]\n",
    "    return shuffled_images, shuffled_labels\n",
    "\n",
    "# 将label从长度10的one hot向量转换为0~9的数字\n",
    "# 例：get_label(total_labels[0]) 获取到total_labels中第一个标签对应的数字\n",
    "def get_label(label):\n",
    "    return np.argmax(label)\n",
    "\n",
    "# images：训练集的feature部分\n",
    "# labels：训练集的label部分\n",
    "# batch_size： 每次训练的batch大小\n",
    "# epoch_num： 训练的epochs数\n",
    "# shuffle： 是否打乱数据\n",
    "# 使用示例：\n",
    "#   for (batchImages, batchLabels) in batch_iter(images_train, labels_train, batch_size, epoch_num, shuffle=True):\n",
    "#       sess.run(feed_dict={inputLayer: batchImages, outputLabel: batchLabels})\n",
    "def batch_iter(images,labels, batch_size, epoch_num, shuffle=True):\n",
    "    data_size = len(images)\n",
    "    num_batches_per_epoch = int(data_size / batch_size)  # 样本数/batch块大小,多出来的“尾数”，不要了\n",
    "    for epoch in range(epoch_num):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data_feature = images[shuffle_indices]\n",
    "            shuffled_data_label   = labels[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data_feature = images\n",
    "            shuffled_data_label = labels\n",
    "        for batch_num in range(num_batches_per_epoch):   # batch_num取值0到num_batches_per_epoch-1\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "\n",
    "            yield (shuffled_data_feature[start_index:end_index] , shuffled_data_label[start_index:end_index])\n",
    "\n",
    "\n",
    "# 读取数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "total_images = mnist.train.images\n",
    "total_labels = mnist.train.labels\n",
    "total_images, total_labels = shuffer_images_and_labels(total_images, total_labels)\n",
    "\n",
    "# 简单划分前50000个为训练集，后5000个为测试集\n",
    "origin_images_train = total_images[:50000]\n",
    "origin_labels_train = total_labels[:50000]\n",
    "origin_images_test = total_images[50000:]\n",
    "origin_labels_test = total_labels[50000:]\n",
    "\n",
    "# 构建和训练模型\n",
    "def train_and_test1(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):\n",
    "    x = tf.placeholder(tf.float32,[None,784],name = \"X\")\n",
    "    y = tf.placeholder(tf.float32,[None,10],name = \"Y\")\n",
    "   \n",
    "    #隐藏层神经元数量\n",
    "    H1_NN = 256#第1隐藏层神经元为256个\n",
    "    H2_NN = 64#第2隐藏层神经元为64个\n",
    "    #输入层 - 第1隐藏层参数和偏置顶\n",
    "    W1 = tf.Variable(tf.truncated_normal([784,H1_NN],stddev = 0.1))\n",
    "    b1 = tf.Variable(tf.zeros([H1_NN]))\n",
    "    #第1隐藏层- 第2隐藏层参数和偏置顶\n",
    "    W2 = tf.Variable(tf.truncated_normal([H1_NN,H2_NN],stddev = 0.1))\n",
    "    b2 = tf.Variable(tf.zeros([H2_NN]))\n",
    "    #第2隐藏层- 输出层\n",
    "    W3 = tf.Variable(tf.truncated_normal([H2_NN,10],stddev = 0.1))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    Y1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "    Y2 = tf.nn.relu(tf.matmul(Y1,W2)+b2)\n",
    "    forward = tf.matmul(Y2,W3)+b3\n",
    "    pred = tf.nn.softmax(forward)\n",
    "    #交叉熵\n",
    "    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward,labels=y))\n",
    "    train_epochs = 40#训练轮数\n",
    "    batch_size = 60#单次训练样本数\n",
    "    total_batch = int(len(images_train)/batch_size)#一轮训练有多少批次\n",
    "    #splay_step = 1#显示粒度\n",
    "    learning_rate = 0.003#学习率\n",
    "    #优化器\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(pred,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    #建立会话\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    count = 1\n",
    "    for (batchImages, batchLabels) in batch_iter(images_train, labels_train, batch_size, train_epochs, shuffle=True):\n",
    "        sess.run(optimizer,feed_dict={x: batchImages, y: batchLabels})\n",
    "        # accu_test = sess.run(accuracy,feed_dict={x:images_test,y:labels_test})\n",
    "        \n",
    "        if count%total_batch== 0:\n",
    "            accu_test = sess.run(accuracy,feed_dict={x:images_test,y:labels_test})\n",
    "            print(\"Accuracy:\",accu_test)  \n",
    "        count += 1\n",
    "    print(\"Final Accuracy:\",sess.run(accuracy,feed_dict={x:images_validation,y:labels_validation}))\n",
    "    sess.close()\n",
    "    print(\"Train finied!\")\n",
    "# 划分数据集并调用train_and_test测试和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\miniconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-d6f1bdba9974>:77: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Accuracy: 0.9584\n",
      "Accuracy: 0.9688\n",
      "Accuracy: 0.9736\n",
      "Accuracy: 0.9742\n",
      "Accuracy: 0.967\n",
      "Accuracy: 0.97\n",
      "Accuracy: 0.9722\n",
      "Accuracy: 0.9734\n",
      "Accuracy: 0.973\n",
      "Accuracy: 0.9734\n",
      "Accuracy: 0.973\n",
      "Accuracy: 0.9748\n",
      "Accuracy: 0.9698\n",
      "Accuracy: 0.9766\n",
      "Accuracy: 0.9732\n",
      "Accuracy: 0.972\n",
      "Accuracy: 0.9746\n",
      "Accuracy: 0.9772\n",
      "Accuracy: 0.978\n",
      "Accuracy: 0.9774\n",
      "Accuracy: 0.9752\n",
      "Accuracy: 0.9754\n",
      "Accuracy: 0.9758\n",
      "Accuracy: 0.973\n",
      "Accuracy: 0.9776\n",
      "Accuracy: 0.9734\n",
      "Accuracy: 0.975\n",
      "Accuracy: 0.9744\n",
      "Accuracy: 0.9706\n",
      "Accuracy: 0.9776\n",
      "Accuracy: 0.9786\n",
      "Accuracy: 0.9726\n",
      "Accuracy: 0.976\n",
      "Accuracy: 0.9762\n",
      "Accuracy: 0.9746\n",
      "Accuracy: 0.9776\n",
      "Accuracy: 0.9788\n",
      "Accuracy: 0.973\n",
      "Accuracy: 0.9802\n",
      "Accuracy: 0.977\n",
      "Final Accuracy: 0.977\n",
      "Train finied!\n",
      "during_time: 119.2706687450409\n"
     ]
    }
   ],
   "source": [
    "# 使用简单划分的训练集和测试集训练，并使用测试集评估模型\n",
    "from time import time\n",
    "start_time=time()\n",
    "train_and_test1(origin_images_train, origin_labels_train, origin_images_test, origin_labels_test, origin_images_test, origin_labels_test)\n",
    "print(\"during_time:\",time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test2(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):\n",
    "    x = tf.placeholder(tf.float32,[None,784],name = \"X\")\n",
    "    y = tf.placeholder(tf.float32,[None,10],name = \"Y\")\n",
    "    #1层隐藏层\n",
    "    ##隐藏层神经元数量\n",
    "    H1_NN = 256\n",
    "    W1 = tf.Variable(tf.random_normal([784,H1_NN]))\n",
    "    b1 = tf.Variable(tf.zeros([H1_NN]))\n",
    "    #激活函数ReLU\n",
    "    Y1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "    #构建输出层\n",
    "    W2 = tf.Variable(tf.random_normal([H1_NN,10]))\n",
    "    b2 = tf.Variable(tf.zeros([10]))\n",
    "    #前向计算\n",
    "    forward = tf.matmul(Y1,W2) + b2\n",
    "    pred = tf.nn.softmax(forward)\n",
    "    #交叉熵\n",
    "    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward,labels=y))\n",
    "    train_epochs = 50#训练轮数\n",
    "    batch_size = 200#单次训练样本数\n",
    "    total_batch = int(len(images_train)/batch_size)#一轮训练有多少批次\n",
    "    learning_rate = 0.01#学习率\n",
    "    #优化器\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(pred,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    #建立会话\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    count = 0\n",
    "    for (batchImages, batchLabels) in batch_iter(images_train, labels_train, batch_size, train_epochs, shuffle=True):\n",
    "        sess.run(optimizer,feed_dict={x: batchImages, y: batchLabels})\n",
    "        if count%total_batch== 0:\n",
    "            accu_test = sess.run(accuracy,feed_dict={x:images_test,y:labels_test})\n",
    "            print(\"Accuracy:\",accu_test)  \n",
    "        count += 1\n",
    "    #accu_validation = sess.run(accuracy,feed_dict={x:images_validation,y:labels_validation})\n",
    "    #print(\"Accuracy:\",accu_validation)\n",
    "    print(\"Accuracy:\",accu_test)\n",
    "    sess.close()\n",
    "  #  return accu_validation.item()\n",
    "    return accu_test.item()\n",
    "# 划分数据集并调用train_and_test测试和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1038\n",
      "Accuracy: 0.916\n",
      "Accuracy: 0.932\n",
      "Accuracy: 0.9406\n",
      "Accuracy: 0.9446\n",
      "Accuracy: 0.9528\n",
      "Accuracy: 0.9548\n",
      "Accuracy: 0.954\n",
      "Accuracy: 0.9598\n",
      "Accuracy: 0.9594\n",
      "Accuracy: 0.9628\n",
      "Accuracy: 0.959\n",
      "Accuracy: 0.9596\n",
      "Accuracy: 0.9598\n",
      "Accuracy: 0.9624\n",
      "Accuracy: 0.9674\n",
      "Accuracy: 0.963\n",
      "Accuracy: 0.96\n",
      "Accuracy: 0.9678\n",
      "Accuracy: 0.962\n",
      "Accuracy: 0.9652\n",
      "Accuracy: 0.964\n",
      "Accuracy: 0.9686\n",
      "Accuracy: 0.9676\n",
      "Accuracy: 0.969\n",
      "Accuracy: 0.97\n",
      "Accuracy: 0.969\n",
      "Accuracy: 0.9708\n",
      "Accuracy: 0.9674\n",
      "Accuracy: 0.9696\n",
      "Accuracy: 0.9678\n",
      "Accuracy: 0.965\n",
      "Accuracy: 0.9686\n",
      "Accuracy: 0.97\n",
      "Accuracy: 0.9696\n",
      "Accuracy: 0.9662\n",
      "Accuracy: 0.9726\n",
      "Accuracy: 0.9692\n",
      "Accuracy: 0.9722\n",
      "Accuracy: 0.974\n",
      "Accuracy: 0.9736\n",
      "Accuracy: 0.9724\n",
      "Accuracy: 0.9736\n",
      "Accuracy: 0.9696\n",
      "Accuracy: 0.9704\n",
      "Accuracy: 0.9672\n",
      "Accuracy: 0.967\n",
      "Accuracy: 0.9704\n",
      "Accuracy: 0.972\n",
      "Accuracy: 0.972\n",
      "Accuracy: 0.972\n",
      "during_time: 65.01522135734558\n"
     ]
    }
   ],
   "source": [
    "# 使用简单划分的训练集和测试集训练，并使用测试集评估模型\n",
    "from time import time\n",
    "start_time=time()\n",
    "train_and_test2(origin_images_train, origin_labels_train, origin_images_test, origin_labels_test, origin_images_test, origin_labels_test)\n",
    "print(\"during_time:\",time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out(images, labels, train_percentage):\n",
    "    images_train,images_test,\\\n",
    "    labels_train,labels_test=train_test_split(images, labels,test_size=train_percentage,random_state=0)\n",
    "    train_and_test2(images_train, labels_train, images_test, labels_test,images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "(5000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(total_images.shape[1])\n",
    "print(origin_images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9738182\n"
     ]
    }
   ],
   "source": [
    "# 调用函数用留出法和k折交叉验证法评估模型\n",
    "hold_out(total_images, total_labels, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9685909\n"
     ]
    }
   ],
   "source": [
    "hold_out(total_images, total_labels, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9670303\n"
     ]
    }
   ],
   "source": [
    "hold_out(total_images, total_labels, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95954543\n"
     ]
    }
   ],
   "source": [
    "hold_out(total_images, total_labels, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9349495\n"
     ]
    }
   ],
   "source": [
    "hold_out(total_images, total_labels, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(images, labels, k):\n",
    "    count1 = 0.0\n",
    "    kf = KFold(n_splits =k,shuffle= True)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(images):\n",
    "        images_train,images_test = images[train_index],images[test_index]\n",
    "        labels_train,labels_test = labels[train_index],labels[test_index]\n",
    "        print(\"Train:\",i)\n",
    "        i +=1\n",
    "        temp=train_and_test2(images_train, labels_train, images_test, labels_test, images_test, labels_test)\n",
    "        count1 = count1 + temp\n",
    "    average = count1/k\n",
    "    print(\"Average:\",average)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1\n",
      "Accuracy: 0.9725\n",
      "Train: 2\n",
      "Accuracy: 0.9671\n",
      "Train: 3\n",
      "Accuracy: 0.9714\n",
      "Train: 4\n",
      "Accuracy: 0.9691\n",
      "Train: 5\n",
      "Accuracy: 0.9697\n",
      "Average: 0.9699600100517273\n"
     ]
    }
   ],
   "source": [
    "cross_validation(origin_images_train, origin_labels_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1\n",
      "Accuracy: 0.9732\n",
      "Train: 2\n",
      "Accuracy: 0.9758\n",
      "Train: 3\n",
      "Accuracy: 0.974\n",
      "Train: 4\n",
      "Accuracy: 0.9676\n",
      "Train: 5\n",
      "Accuracy: 0.9716\n",
      "Train: 6\n",
      "Accuracy: 0.9702\n",
      "Train: 7\n",
      "Accuracy: 0.9702\n",
      "Train: 8\n",
      "Accuracy: 0.9734\n",
      "Train: 9\n",
      "Accuracy: 0.9672\n",
      "Train: 10\n",
      "Accuracy: 0.9676\n",
      "Average: 0.9710799932479859\n"
     ]
    }
   ],
   "source": [
    "cross_validation(origin_images_train, origin_labels_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7f45b3046234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_images_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"during_time:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time=time()\n",
    "cross_validation(origin_images_train, origin_labels_train, 15)\n",
    "print(\"during_time:\",time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
